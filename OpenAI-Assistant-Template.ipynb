{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "M5orGgGyNfaL",
      "metadata": {
        "id": "M5orGgGyNfaL"
      },
      "source": [
        "# You can use this as a template to quickly create an Assistant using OpenAI's Assistant API"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xKSjxcGnNfaM",
      "metadata": {
        "id": "xKSjxcGnNfaM"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OS8AK6dpTNR_",
      "metadata": {
        "id": "OS8AK6dpTNR_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SMV8CbeuQHWY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMV8CbeuQHWY",
        "outputId": "0fc73e21-630c-43d8-c3ba-7c94215c66e4"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b21fdf7e-c27e-493c-b9d2-dbcc6ef61abb",
      "metadata": {
        "id": "b21fdf7e-c27e-493c-b9d2-dbcc6ef61abb"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "OPENAI_KEY = userdata.get('OPENAI_KEY')\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_KEY) # Initialize OpenAI Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VJ0ZoGrbQ04P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ0ZoGrbQ04P",
        "outputId": "e91fa0e0-82b8-49ac-b9ea-ec577a4d7bd6"
      },
      "outputs": [],
      "source": [
        "!pip show openai | grep Version"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hQc1PCGUNfaN",
      "metadata": {
        "id": "hQc1PCGUNfaN"
      },
      "source": [
        "### You can start an assistant from scratch or even use an already made assistant on a thread made from scratch\n",
        "\n",
        "-> For Assistants -\n",
        "* Set ```get_premade_assistant = False``` to create a new assistant.\n",
        "* Set ```get_premade_assistant = True``` if you want to use a previous assistant.\n",
        "\n",
        "-> For Threads -\n",
        "* Set ```get_previous_thread = False``` to create a new thread.\n",
        "* Set ```get_previous_thread = True``` if you want to use a previous thread.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GCkLcCN0NfaO",
      "metadata": {
        "id": "GCkLcCN0NfaO"
      },
      "outputs": [],
      "source": [
        "get_premade_assistant = False\n",
        "get_previous_thread = False\n",
        "\n",
        "assistant_id_to_use = \"asst_6waRJUR4EfaVRYWLkqetgSuu\"\n",
        "thread_id_to_use = \"thread_bBkIkcD7yZW3QtrIYt6GMj5e\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xpTeqGBG_Br2",
      "metadata": {
        "id": "xpTeqGBG_Br2"
      },
      "source": [
        "## Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Es296U1V_J30",
      "metadata": {
        "id": "Es296U1V_J30"
      },
      "outputs": [],
      "source": [
        "from tempfile import NamedTemporaryFile\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "import requests\n",
        "\n",
        "\n",
        "def generate_image(prompt, n:int=1, size:str=\"1024x1024\"):\n",
        "    global client\n",
        "    response = client.images.generate(\n",
        "      model=\"dall-e-3\",\n",
        "      prompt=prompt,\n",
        "      size=size,\n",
        "      quality=\"standard\",\n",
        "      n=1\n",
        "    )\n",
        "\n",
        "    image_url = response.data[0].url\n",
        "\n",
        "    im = Image.open(requests.get(image_url, stream=True).raw)\n",
        "    im.save(\"temp.png\")\n",
        "\n",
        "    import cv2\n",
        "    img = cv2.imread('temp.png', cv2.IMREAD_UNCHANGED)\n",
        "    cv2_imshow(img)\n",
        "\n",
        "\n",
        "    return image_url\n",
        "\n",
        "def generate_image_consistent(prompt, n:int=1, size:str=\"1024x1024\"):\n",
        "    global client\n",
        "    print('consistent with ', imagegen_ledger['image_url'], imagegen_ledger['description'])\n",
        "    response = client.images.generate(\n",
        "      model=\"dall-e-3\",\n",
        "      prompt=imagegen_ledger['description'] + \" \" + prompt,\n",
        "      size=size,\n",
        "      quality=\"standard\",\n",
        "      n=1\n",
        "    )\n",
        "\n",
        "    image_url = response.data[0].url\n",
        "\n",
        "    im = Image.open(requests.get(image_url, stream=True).raw)\n",
        "    im.save(\"temp-consistent.png\")\n",
        "\n",
        "    import cv2\n",
        "    img = cv2.imread('temp-consistent.png', cv2.IMREAD_UNCHANGED)\n",
        "    cv2_imshow(img)\n",
        "\n",
        "\n",
        "    return image_url"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "describe_system_prompt = '''\n",
        "    You are a system generating descriptions of a detailed character for a role-playing game, including their background, profession, skills, and a unique personal quirk.\n",
        "Describe the detailed character(human/non-human, gender, age) , scenario(theme, background), style(Real-Time, Realistic, Cartoon, Anime, Manga, Surreal) and resolution(SD, HD, QHD, 4k, 8k)\n",
        "    Provided with an image and a title, you will describe the main subject that you see in the image, giving details that will be used to describe and maintain consistency with the main subject when new images are generated with the image generation model.\n",
        "    You can describe unambiguously what the item is.\n",
        "    '''\n",
        "\n",
        "def describe_image(img_url, title):\n",
        "    global client\n",
        "    response = client.chat.completions.create(\n",
        "    model=\"gpt-4-vision-preview\",\n",
        "    temperature=0.2,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": describe_system_prompt\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": img_url,\n",
        "                },\n",
        "            ],\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": title\n",
        "        }\n",
        "    ],\n",
        "    max_tokens=300,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "esSQvrROZ0v5"
      },
      "id": "esSQvrROZ0v5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w3qo2vIWbCRD"
      },
      "id": "w3qo2vIWbCRD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gGJeqQs28H7q",
      "metadata": {
        "id": "gGJeqQs28H7q"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Description: \"Run the thread with the assistant\"\n",
        "def run_chat(client, thread, assistant):\n",
        "    run = client.beta.threads.runs.create(\n",
        "    thread_id=thread.id,\n",
        "    assistant_id=assistant.id,\n",
        "    )\n",
        "    return run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K4CAH1Ne8Qan",
      "metadata": {
        "id": "K4CAH1Ne8Qan"
      },
      "outputs": [],
      "source": [
        "# Description: \"Create a new Assistant\"\n",
        "\n",
        "def create_assistant(client, name, description, instructions, tools=[], model=\"gpt-3.5-turbo-1106\"):\n",
        "    assistant = client.beta.assistants.create(\n",
        "    name=name,\n",
        "    description=description,\n",
        "    instructions=instructions,\n",
        "    tools=tools,\n",
        "    model=model\n",
        "    )\n",
        "\n",
        "    print(f\"Debugging: Useful for checking the generated agent in the playground. https://platform.openai.com/playground?mode=assistant&assistant={assistant.id}\")\n",
        "\n",
        "\n",
        "    return assistant\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kFZTQrdl8Vg8",
      "metadata": {
        "id": "kFZTQrdl8Vg8"
      },
      "outputs": [],
      "source": [
        "# Description: \"Get an already made assistant\"\n",
        "\n",
        "def get_assistant(client, assistant_id):\n",
        "    assistant = client.beta.assistants.retrieve(assistant_id)\n",
        "    return assistant\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SWzc0tW38eNc",
      "metadata": {
        "id": "SWzc0tW38eNc"
      },
      "outputs": [],
      "source": [
        "# Description: \"Start a new chat with a user\"\n",
        "\n",
        "def start_new_chat(client):\n",
        "    empty_thread = client.beta.threads.create()\n",
        "    print(f\"Debugging: Useful for checking logs. https://platform.openai.com/playground?thread={empty_thread.id}\")\n",
        "    return empty_thread\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y-hP65XY8gKx",
      "metadata": {
        "id": "Y-hP65XY8gKx"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Description: Retrieve previous chat/Thread\n",
        "\n",
        "def get_chat(client, thread_id):\n",
        "    thread = client.beta.threads.retrieve(thread_id)\n",
        "    print(f\"Debugging: Useful for checking logs. https://platform.openai.com/playground?thread={thread.id}\")\n",
        "    return thread\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YAWoFkUb8iKb",
      "metadata": {
        "id": "YAWoFkUb8iKb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Description: \"Add a message to a chat/Thread\"\n",
        "\n",
        "def add_message(client, thread, content):\n",
        "    thread_message = client.beta.threads.messages.create(\n",
        "    thread_id = thread.id,\n",
        "    role=\"user\",\n",
        "    content=content,\n",
        "    )\n",
        "    return thread_message\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hlRUdOS08kJS",
      "metadata": {
        "id": "hlRUdOS08kJS"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Description: \"Get the previous messages in a chat/Thread\"\n",
        "def get_messages_in_chat(client, thread):\n",
        "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
        "    return messages\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eRNKpWWGNfaO",
      "metadata": {
        "id": "eRNKpWWGNfaO"
      },
      "source": [
        "### Get Assistant using assistant id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S6Ac7JQC5TnJ",
      "metadata": {
        "id": "S6Ac7JQC5TnJ"
      },
      "outputs": [],
      "source": [
        "instructions_imagegen = \"\"\"\n",
        "When creating an image, use the provided generate_image function to return the image, using the imageDes from the output JSON as the required prompt parameter to provided generate_image function.\n",
        "\"\"\"\n",
        "imagegen_ledger = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mX0XUHSe5M_w",
      "metadata": {
        "id": "mX0XUHSe5M_w"
      },
      "outputs": [],
      "source": [
        "tools_imagegen = [{\n",
        "              \"type\": \"function\",\n",
        "              \"function\": {\n",
        "                \"name\": \"generate_image\",\n",
        "                \"description\": \"generate image by Dall-e 3\",\n",
        "                \"parameters\": {\n",
        "                  \"type\": \"object\",\n",
        "                  \"properties\": {\n",
        "                    \"prompt\": {\"type\": \"string\", \"description\": \"The prompt to generate image\"},\n",
        "                    \"size\": {\"type\": \"string\", \"enum\": [\"c\", \"f\"]}\n",
        "                  },\n",
        "                  \"required\": [\"prompt\"]\n",
        "                }\n",
        "              }\n",
        "            }]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ANkqxiVFNfaO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANkqxiVFNfaO",
        "outputId": "223a13e0-5370-430e-faf9-4a7b5bdb5d1a"
      },
      "outputs": [],
      "source": [
        "if get_premade_assistant:\n",
        "    assistant = get_assistant(client, assistant_id_to_use) # Retrieve Assistant\n",
        "    print(assistant.name + \" is ready to go!\")\n",
        "else:\n",
        "    name = \"Role Generation\"\n",
        "    description = \"Near8 Narrative Designer\"\n",
        "    instructions = \"You are a narrative designer who designs unique roles based on Club details and User interests\\\n",
        "        Describe their role incorporating the chosen interests without naming them explicitly\\\n",
        "        Do not use the following words in output: 'fantasy, comedy, nature, time travel, cats, horror, true crime, sports, dogs, pop stars, travel, history, romcom, video games, anime, blockchain, asmr, cottagecore'\\\n",
        "        These roles are defined with a name and an attractive description assigned to a user\\\n",
        "        Make sure to create the name as a character name, a first name and a last name that belongs to a fantasy superhero world\\\n",
        "        Create an image for the role, limit it in one line\\\n",
        "        Use a few emojis in output\\\n",
        "        Provide the output in JSON structure like this {'roleName': '<The name of the role>', 'roleDescription': '<The descritpion of the role>',  'imageDes' : '<The image>'}\" + instructions_imagegen\n",
        "    tools = [\n",
        "        {type: \"code_interpreter\"},\n",
        "        {type: \"retrieval\"}\n",
        "    ] + tools_imagegen\n",
        "    assistant = create_assistant(client, name, description, instructions) # Create Assistant\n",
        "    print(\"New Assistant created with ID: \" + assistant.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Zj3keb9pNfaO",
      "metadata": {
        "id": "Zj3keb9pNfaO"
      },
      "source": [
        "### Retrieve the previous conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jOr-eR9dNfaO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOr-eR9dNfaO",
        "outputId": "9562d25a-0b4f-408e-bb48-5f55a9682e21"
      },
      "outputs": [],
      "source": [
        "# Retrieve the previous conversation thread\n",
        "\n",
        "if get_previous_thread:\n",
        "    thread = get_chat(client, thread_id_to_use)\n",
        "    print(\"Chat retrieved with ID: \" + thread.id)\n",
        "    print(thread)\n",
        "else:\n",
        "    thread = start_new_chat(client)\n",
        "    print(\"New chat created with ID: \" + thread.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QebYsP0jNfaP",
      "metadata": {
        "id": "QebYsP0jNfaP"
      },
      "source": [
        "### Add new message into thread"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w-2g4vZhNfaP",
      "metadata": {
        "id": "w-2g4vZhNfaP"
      },
      "outputs": [],
      "source": [
        "# Message to send to the assistant\n",
        "\n",
        "content = '\"Club Name: Vampires Of Brooklyn , User Interests : Yoga, Cycling, Tech , AI\"'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kJW5z8uSNfaP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJW5z8uSNfaP",
        "outputId": "7a5489a4-8826-4a38-a8ce-1da29b647348"
      },
      "outputs": [],
      "source": [
        "# Add the message into the thread\n",
        "\n",
        "new_message = add_message(client, thread, content)\n",
        "print(new_message)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "J_0N9KECNfaP",
      "metadata": {
        "id": "J_0N9KECNfaP"
      },
      "source": [
        "### Run the thread with the new message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_OAeO19LNfaP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OAeO19LNfaP",
        "outputId": "e279db90-f096-46f9-8816-441cba3e4f31"
      },
      "outputs": [],
      "source": [
        "# Run the thread with the assistant with the new message\n",
        "\n",
        "run_chat(client, thread, assistant)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1RK84d_oNfaP",
      "metadata": {
        "id": "1RK84d_oNfaP"
      },
      "source": [
        "# Run the below code everytime you need to see the new chats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dvyT5DYGNfaP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvyT5DYGNfaP",
        "outputId": "4f75a131-61dd-4a6b-af4b-7cdada6a9d01"
      },
      "outputs": [],
      "source": [
        "# Retrieve the chat history\n",
        "\n",
        "history = get_messages_in_chat(client, thread)\n",
        "messages = history.data[::-1]\n",
        "for i in messages:\n",
        "    print(i.role.upper() + \": \"+ i.content[0].text.value)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9REIXS8Dwg2Q",
      "metadata": {
        "id": "9REIXS8Dwg2Q"
      },
      "source": [
        "# Multi Assistant Runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cXbOdlcVkORT",
      "metadata": {
        "id": "cXbOdlcVkORT"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def show_json(obj):\n",
        "    display(json.loads(obj.model_dump_json()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4RedXIHQ4gLN",
      "metadata": {
        "id": "4RedXIHQ4gLN"
      },
      "outputs": [],
      "source": [
        "def threadMessageLog(thread):\n",
        "  global role_name\n",
        "  # Show the final results\n",
        "\n",
        "\n",
        "  messages = client.beta.threads.messages.list(\n",
        "    thread_id=thread.id\n",
        "  )\n",
        "  message_dict = json.loads(messages.model_dump_json())\n",
        "  # print(message_dict['data'][0]['content'][0][\"text\"][\"value\"])\n",
        "  print(message_dict)\n",
        "  print(messages)\n",
        "\n",
        "  # Save the text of the messages so that they can be printed in reverse order\n",
        "  messageStore = []\n",
        "\n",
        "  for message in messages:\n",
        "      if message.assistant_id == assistantRoleGeneration.id:\n",
        "          assistantName = \"Role: \"\n",
        "\n",
        "          # prompt: set a var role_name that extracts the value from a json that may have the attribute roleName. Check that the string is json and that the attribute exists before setting the var\n",
        "          print('parse')\n",
        "          print(message.content[0].text.value)\n",
        "          try:\n",
        "              parsed_json = json.loads(message.content[0].text.value)\n",
        "              if \"roleName\" in parsed_json:\n",
        "                  role_name = parsed_json[\"roleName\"]\n",
        "                  print(f\"Role name extracted: {role_name}\")\n",
        "              else:\n",
        "                  print(\"JSON does not contain 'roleName' attribute\")\n",
        "          except ValueError as e:\n",
        "              print(f\"Invalid JSON: {e}\")\n",
        "              print(message)\n",
        "              print(message.content[0].text.value)\n",
        "\n",
        "\n",
        "      elif message.assistant_id == assistantPostGeneration.id:\n",
        "          assistantName = \"Post: \"\n",
        "\n",
        "      messageStore.append(assistantName+message.content[0].text.value)\n",
        "\n",
        "  #To make it more readable print the messages in reversed order\n",
        "\n",
        "  for message in reversed(messageStore):\n",
        "      print(message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yvatuu25TP1A",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvatuu25TP1A",
        "outputId": "862ad873-f732-453b-9a32-3ea9dcafc1f7"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "name = \"Role Generation\"\n",
        "description = \"Near8 Role Designer\"\n",
        "instructions = \"You are a narrative designer who designs unique roles based on Club details and User interests\\\n",
        "        Describe their role incorporating the chosen interests without naming them explicitly\\\n",
        "        Do not use the following words in output: 'fantasy, comedy, nature, time travel, cats, horror, true crime, sports, dogs, pop stars, travel, history, romcom, video games, anime, blockchain, asmr, cottagecore'\\\n",
        "        These roles are defined with a name and an attractive description assigned to a user\\\n",
        "        Make sure to create the name as a character name, a first name and a last name that belongs to a fantasy superhero world\\\n",
        "        Create an image for the role, limit it in one line\\\n",
        "        Use a few emojis in output\\\n",
        "        Provide the output in JSON structure like this {\\\"roleName\\\": \\\"<The name of the role>\\\", \\\"roleDescription\\\": \\\"<The descritpion of the role>\\\",  \\\"imageDes\\\" : \\\"<The image>\\\"}\" + instructions_imagegen\n",
        "tools = [\n",
        "        {\n",
        "              \"type\": \"function\",\n",
        "              \"function\": {\n",
        "                \"name\": \"generate_image\",\n",
        "                \"description\": \"generate image by Dall-e 3\",\n",
        "                \"parameters\": {\n",
        "                  \"type\": \"object\",\n",
        "                  \"properties\": {\n",
        "                    \"prompt\": {\"type\": \"string\", \"description\": \"The prompt to generate image\"},\n",
        "                    \"size\": {\"type\": \"string\", \"enum\": [\"c\", \"f\"]}\n",
        "                  },\n",
        "                  \"required\": [\"prompt\"]\n",
        "                }\n",
        "              }\n",
        "        }\n",
        "    ]\n",
        "assistantRoleGeneration = create_assistant(client,name,description,instructions,tools)\n",
        "print(\"Role Generation Assistant created with ID: \" + assistantRoleGeneration.id)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DVTRofbEXdgn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVTRofbEXdgn",
        "outputId": "849df351-fa02-499e-9f3b-16b28ac36b51"
      },
      ],
      "source": [
        "instructions_imagegen_post = \"\"\"\n",
        "When creating an image, use the provided generate_image_consistent function to return the image, using the op0 image from the output JSON as the required prompt parameter to provided generate_image_consistent function.\n",
        "\"\"\"\n",
        "name = \"Post Generation\"\n",
        "description = \"Near8 Post Designer\"\n",
        "instructions = \"You are a narrative designer who designs post and a fortune cookie message using user input\\\n",
        "Make sure the caption is short, tweet-sized one-sentence plot points to flesh out an existing storyline\\\n",
        "Make sure that fortune cookie message in the format of social post like instagram with a limit of 60 words\\\n",
        "Assign a catchy name to this post and use a few emojis in post\\\n",
        "Describe an image in 80 words of this post in a paragraph, don't use any special character, well detailed character(human/non-human, gender, age), scenario(theme, background), style(Real-Time, Realistic, Cartoon, Anime, Manga, Surreal) and resolution(SD, HD, QHD, 4k, 8k)\\\n",
        "Provide the output in JSON structure like this {\\\"op1\\\": \\\"<name>\\\", \\\"op2\\\": \\\"<caption>\\\", \\\"op3\\\": \\\"<fortune-cookie>\\\",  \\\"op0\\\" : \\\"<the image>\\\"} Make sure the output response is a json object where string objects are  key value pair.\" + instructions_imagegen_post\n",
        "tools = [\n",
        "        {\n",
        "              \"type\": \"function\",\n",
        "              \"function\": {\n",
        "                \"name\": \"generate_image_consistent\",\n",
        "                \"description\": \"generate image by Dall-e 3\",\n",
        "                \"parameters\": {\n",
        "                  \"type\": \"object\",\n",
        "                  \"properties\": {\n",
        "                    \"prompt\": {\"type\": \"string\", \"description\": \"The prompt to generate image\"},\n",
        "                    \"size\": {\"type\": \"string\", \"enum\": [\"c\", \"f\"]}\n",
        "                  },\n",
        "                  \"required\": [\"prompt\"]\n",
        "                }\n",
        "              }\n",
        "        }\n",
        "    ]\n",
        "assistantPostGeneration = create_assistant(client,name,description,instructions, tools)\n",
        "print(\"Post Generation Assistant created with ID: \" + assistantPostGeneration.id)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BCxZeiuvkVFI",
      "metadata": {
        "id": "BCxZeiuvkVFI"
      },
      "outputs": [],
      "source": [
        "def wait_on_run(run, thread):\n",
        "    global imagegen_ledger\n",
        "    while run.status == \"queued\" or run.status == \"in_progress\":\n",
        "        run = client.beta.threads.runs.retrieve(\n",
        "            thread_id=thread.id,\n",
        "            run_id=run.id,\n",
        "        )\n",
        "        time.sleep(0.5)\n",
        "\n",
        "        # At this point, the status is either \"completed\" or \"requires_action\"\n",
        "        if run.status == \"completed\":\n",
        "            return client.beta.threads.messages.list(\n",
        "              thread_id=thread.id\n",
        "            )\n",
        "        if run.status == \"requires_action\":\n",
        "            tool_outputs = []\n",
        "            for tool_call in run.required_action.submit_tool_outputs.tool_calls:\n",
        "              print(tool_call.function.name)\n",
        "              if tool_call.function.name == \"generate_image\":\n",
        "                  prompt = json.loads(tool_call.function.arguments)['prompt']\n",
        "                  image_url = generate_image(prompt)\n",
        "                  imagegen_ledger['url'] = image_url\n",
        "                  imagegen_ledger['thread_id'] = thread.id\n",
        "                  imagegen_ledger['prompt'] = prompt\n",
        "                  print('imageurl', image_url)\n",
        "                  image_description = describe_image(image_url, prompt)\n",
        "                  imagegen_ledger['description'] = image_description\n",
        "                  tool_outputs.append(\n",
        "                      {\n",
        "                            \"tool_call_id\": tool_call.id,\n",
        "                            \"output\": image_url,\n",
        "                      },\n",
        "                  )\n",
        "                  print('tool outputs append', tool_outputs)\n",
        "\n",
        "              if tool_call.function.name == \"generate_image_consistent\":\n",
        "                  prompt = json.loads(tool_call.function.arguments)['prompt']\n",
        "                  image_url = generate_image_consistent(prompt)\n",
        "                  print('imageurl consistent', image_url)\n",
        "                  tool_outputs.append(\n",
        "                      {\n",
        "                            \"tool_call_id\": tool_call.id,\n",
        "                            \"output\": image_url,\n",
        "                      },\n",
        "                  )\n",
        "                  print('tool consistent outputs append', tool_outputs)\n",
        "\n",
        "\n",
        "              if run.required_action.type == 'submit_tool_outputs':\n",
        "                  print(\"Submit output\")\n",
        "                  run = client.beta.threads.runs.submit_tool_outputs(\n",
        "                          thread_id=thread.id,\n",
        "                          run_id=run.id,\n",
        "                          tool_outputs=tool_outputs\n",
        "                  )\n",
        "                  print('tool outputs submit',thread.id,run.id, tool_outputs)\n",
        "\n",
        "\n",
        "\n",
        "    return run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Uj2ARxVtUZkG",
      "metadata": {
        "id": "Uj2ARxVtUZkG"
      },
      "outputs": [],
      "source": [
        "\n",
        "def runAssistant(assistant_id,thread_id):\n",
        "    run = client.beta.threads.runs.create(\n",
        "        thread_id=thread_id,\n",
        "        assistant_id=assistant_id\n",
        "    )\n",
        "    print(f'Run Assistant Created {run.id}')\n",
        "    return run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NCNAef5P7NpE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "NCNAef5P7NpE",
        "outputId": "408462c4-b9b3-4227-e28f-57de6a704c7c"
      },
      "outputs": [],
      "source": [
        "# create new thread per new user input\n",
        "\n",
        "threadDuo = client.beta.threads.create()\n",
        "print(f\"Debugging: Useful for checking logs. https://platform.openai.com/playground?thread={threadDuo.id}\")\n",
        "\n",
        "show_json(threadDuo)\n",
        "\n",
        "# prompt: ask the user to input Club Name, and User Interests. Then, save it into a var content like such content = '\"Club Name: DJs Of Brooklyn , User Interests : Rowing, Surfing, Tech , AI\"'\n",
        "\n",
        "club_name = input(\"Enter Club Name: \")\n",
        "user_interests = input(\"Enter User Interests: \")\n",
        "content = '\"Club Name: {}, User Interests : {}\"'.format(club_name, user_interests)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y_C85cY4UVLX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "Y_C85cY4UVLX",
        "outputId": "c3735ca6-bb87-4e29-966a-d933148a3080"
      },
      "outputs": [],
      "source": [
        "print(content)\n",
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=threadDuo.id,\n",
        "    role=\"user\",\n",
        "    content=content,\n",
        ")\n",
        "\n",
        "show_json(message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jiUTYi_yUcIa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiUTYi_yUcIa",
        "outputId": "81de2b1e-4de3-4fd5-8d4a-81f82248fec7"
      },
      "outputs": [],
      "source": [
        "# Run the Role Assistant to create a first draft\n",
        "run = runAssistant(assistantRoleGeneration.id,threadDuo.id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G8cZQyWPqDFe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        },
        "id": "G8cZQyWPqDFe",
        "outputId": "4b94e52a-975e-4550-8570-98d5e4405048"
      },
      "outputs": [],
      "source": [
        "run = wait_on_run(run, threadDuo)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(imagegen_ledger)\n",
        "print(imagegen_ledger['description'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIiFQwWRF-Mv",
        "outputId": "76e880ab-7fcc-40a5-e4cf-aa11afdcf190"
      },
      "id": "HIiFQwWRF-Mv",
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VsKGdfWA8pOY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsKGdfWA8pOY",
        "outputId": "40c4a9af-7291-404d-b8ba-95e45d9ad299"
      },
      "outputs": [],
      "source": [
        "threadMessageLog(threadDuo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ee5ZR4wU-ShC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "Ee5ZR4wU-ShC",
        "outputId": "69776039-0f3e-47e9-b5d9-5dd26db58a76"
      },
      "outputs": [],
      "source": [
        "show_json(run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jcF5-ziK-haP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcF5-ziK-haP",
        "outputId": "003caac2-2c01-492c-cba4-ed5c48245674"
      },
      "outputs": [],
      "source": [
        "# prompt: ask the user to input a time hook description, a place.\n",
        "\n",
        "time_hook = input(\"Enter a time hook description: \")\n",
        "place = input(\"Enter a place: \")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cjqaQg2kBl2s",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjqaQg2kBl2s",
        "outputId": "08878273-ec33-44c1-c08b-0470e722defb"
      },
      "outputs": [],
      "source": [
        "# prompt: set var postContent with time hook, place, roleName, and clubName e.g. \"python day, online ,Sufer Moonlight, DJs of Brooklyn\"\n",
        "\n",
        "postContent = \"{}, {}, {}, {}\".format(time_hook, place, role_name, club_name)\n",
        "print(postContent)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B0G4jMumBjAH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "B0G4jMumBjAH",
        "outputId": "89e47484-9081-41c3-9a25-6b12e1b8d17e"
      },
      "outputs": [],
      "source": [
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=threadDuo.id,\n",
        "    role=\"user\",\n",
        "    content=postContent,\n",
        ")\n",
        "\n",
        "show_json(message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YgYC1h8CUvX_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgYC1h8CUvX_",
        "outputId": "603f16c6-88d6-4931-8e76-7c4b5df11a8a"
      },
      "outputs": [],
      "source": [
        "# Run the Post Assistant\n",
        "run_post = runAssistant(assistantPostGeneration.id,threadDuo.id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TmQ_EV9dsJ8c",
      "metadata": {
        "id": "TmQ_EV9dsJ8c"
      },
      "outputs": [],
      "source": [
        "run_post = wait_on_run(run_post, threadDuo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DAB-JLJuwNKn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAB-JLJuwNKn",
        "outputId": "e5888be2-968a-4216-9cf9-d9419b3ac88b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Show the final results\n",
        "\n",
        "messages = client.beta.threads.messages.list(\n",
        "  thread_id=threadDuo.id\n",
        ")\n",
        "\n",
        "\n",
        "# Save the text of the messages so that they can be printed in reverse order\n",
        "messageStore = []\n",
        "\n",
        "for message in messages:\n",
        "\n",
        "    if message.assistant_id == assistantRoleGeneration.id:\n",
        "        assistantName = \"Role: \"\n",
        "    elif message.assistant_id == assistantPostGeneration.id:\n",
        "        assistantName = \"Post: \"\n",
        "\n",
        "    messageStore.append(assistantName+message.content[0].text.value)\n",
        "\n",
        "#To make it more readable print the messages in reversed order\n",
        "\n",
        "for message in reversed(messageStore):\n",
        "    print(message)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
